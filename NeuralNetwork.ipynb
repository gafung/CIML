{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "import pandas as pd\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"data_knn2.csv\"\n",
    "\n",
    "dataframe = pd.read_csv(url, header=0)\n",
    "\n",
    "## Create an 'X' matrix by dropping the irrelevant columns.\n",
    "X = dataframe[['type_num', 'size_adv', \"size_out_pct\", \"days_fm_last\", \"mkt_cap\"]]\n",
    "Y = dataframe['return_30d_num'].replace(-1, 0)\n",
    "\n",
    "X_train = X.head(3000).as_matrix()\n",
    "X_test = X.tail(X.shape[0] - 3000).as_matrix()\n",
    "Y_train = Y.head(3000).as_matrix()\n",
    "Y_test = Y.tail(X.shape[0] - 3000).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=5, activation='tanh'))\n",
    "model.add(Dense(200, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3000/3000 [==============================] - 2s 504us/step - loss: 0.7175 - acc: 0.5117\n",
      "Epoch 2/100\n",
      "3000/3000 [==============================] - 1s 341us/step - loss: 0.7064 - acc: 0.5153\n",
      "Epoch 3/100\n",
      "3000/3000 [==============================] - 1s 345us/step - loss: 0.7007 - acc: 0.5197\n",
      "Epoch 4/100\n",
      "3000/3000 [==============================] - 1s 341us/step - loss: 0.6998 - acc: 0.5210\n",
      "Epoch 5/100\n",
      "3000/3000 [==============================] - 1s 346us/step - loss: 0.7030 - acc: 0.5167\n",
      "Epoch 6/100\n",
      "3000/3000 [==============================] - 1s 345us/step - loss: 0.7004 - acc: 0.5057\n",
      "Epoch 7/100\n",
      "3000/3000 [==============================] - 1s 357us/step - loss: 0.7006 - acc: 0.4983\n",
      "Epoch 8/100\n",
      "3000/3000 [==============================] - 1s 344us/step - loss: 0.6998 - acc: 0.5093\n",
      "Epoch 9/100\n",
      "3000/3000 [==============================] - 1s 347us/step - loss: 0.7049 - acc: 0.4873\n",
      "Epoch 10/100\n",
      "3000/3000 [==============================] - 1s 349us/step - loss: 0.6993 - acc: 0.5070\n",
      "Epoch 11/100\n",
      "3000/3000 [==============================] - 1s 407us/step - loss: 0.7057 - acc: 0.4950\n",
      "Epoch 12/100\n",
      "3000/3000 [==============================] - 1s 362us/step - loss: 0.7048 - acc: 0.4933\n",
      "Epoch 13/100\n",
      "3000/3000 [==============================] - 1s 358us/step - loss: 0.7014 - acc: 0.4973\n",
      "Epoch 14/100\n",
      "3000/3000 [==============================] - 1s 447us/step - loss: 0.7001 - acc: 0.5110\n",
      "Epoch 15/100\n",
      "3000/3000 [==============================] - 1s 371us/step - loss: 0.6994 - acc: 0.5117\n",
      "Epoch 16/100\n",
      "3000/3000 [==============================] - 1s 373us/step - loss: 0.6995 - acc: 0.4970\n",
      "Epoch 17/100\n",
      "3000/3000 [==============================] - 1s 426us/step - loss: 0.7022 - acc: 0.5020\n",
      "Epoch 18/100\n",
      "3000/3000 [==============================] - 1s 401us/step - loss: 0.7000 - acc: 0.5110\n",
      "Epoch 19/100\n",
      "3000/3000 [==============================] - 1s 378us/step - loss: 0.6982 - acc: 0.5317\n",
      "Epoch 20/100\n",
      "3000/3000 [==============================] - 1s 367us/step - loss: 0.7008 - acc: 0.5143\n",
      "Epoch 21/100\n",
      "3000/3000 [==============================] - 1s 372us/step - loss: 0.6991 - acc: 0.5160\n",
      "Epoch 22/100\n",
      "3000/3000 [==============================] - 1s 365us/step - loss: 0.6994 - acc: 0.5080\n",
      "Epoch 23/100\n",
      "3000/3000 [==============================] - 1s 362us/step - loss: 0.7025 - acc: 0.5093\n",
      "Epoch 24/100\n",
      "3000/3000 [==============================] - 1s 375us/step - loss: 0.6975 - acc: 0.5160\n",
      "Epoch 25/100\n",
      "3000/3000 [==============================] - 1s 369us/step - loss: 0.6968 - acc: 0.5150\n",
      "Epoch 26/100\n",
      "3000/3000 [==============================] - 1s 371us/step - loss: 0.7029 - acc: 0.5000\n",
      "Epoch 27/100\n",
      "3000/3000 [==============================] - 1s 366us/step - loss: 0.7023 - acc: 0.4980\n",
      "Epoch 28/100\n",
      "3000/3000 [==============================] - 1s 367us/step - loss: 0.6974 - acc: 0.5097\n",
      "Epoch 29/100\n",
      "3000/3000 [==============================] - 1s 367us/step - loss: 0.7006 - acc: 0.5143\n",
      "Epoch 30/100\n",
      "3000/3000 [==============================] - 1s 365us/step - loss: 0.6966 - acc: 0.5157\n",
      "Epoch 31/100\n",
      "3000/3000 [==============================] - 1s 369us/step - loss: 0.6990 - acc: 0.5227\n",
      "Epoch 32/100\n",
      "3000/3000 [==============================] - 1s 363us/step - loss: 0.7017 - acc: 0.5037\n",
      "Epoch 33/100\n",
      "3000/3000 [==============================] - 1s 375us/step - loss: 0.6988 - acc: 0.5187\n",
      "Epoch 34/100\n",
      "3000/3000 [==============================] - 1s 372us/step - loss: 0.6977 - acc: 0.5137\n",
      "Epoch 35/100\n",
      "3000/3000 [==============================] - 1s 361us/step - loss: 0.7002 - acc: 0.5210\n",
      "Epoch 36/100\n",
      "3000/3000 [==============================] - 1s 362us/step - loss: 0.6978 - acc: 0.5060\n",
      "Epoch 37/100\n",
      "3000/3000 [==============================] - 1s 368us/step - loss: 0.6973 - acc: 0.5050\n",
      "Epoch 38/100\n",
      "3000/3000 [==============================] - 1s 371us/step - loss: 0.7006 - acc: 0.5123\n",
      "Epoch 39/100\n",
      "3000/3000 [==============================] - 1s 365us/step - loss: 0.6985 - acc: 0.5173\n",
      "Epoch 40/100\n",
      "3000/3000 [==============================] - 1s 361us/step - loss: 0.6968 - acc: 0.5200\n",
      "Epoch 41/100\n",
      "3000/3000 [==============================] - 1s 366us/step - loss: 0.6969 - acc: 0.5177\n",
      "Epoch 42/100\n",
      "3000/3000 [==============================] - 1s 362us/step - loss: 0.6939 - acc: 0.5140\n",
      "Epoch 43/100\n",
      "3000/3000 [==============================] - 1s 369us/step - loss: 0.6949 - acc: 0.5263\n",
      "Epoch 44/100\n",
      "3000/3000 [==============================] - 1s 376us/step - loss: 0.6936 - acc: 0.5197\n",
      "Epoch 45/100\n",
      "3000/3000 [==============================] - 1s 361us/step - loss: 0.6964 - acc: 0.5163\n",
      "Epoch 46/100\n",
      "3000/3000 [==============================] - 1s 386us/step - loss: 0.6995 - acc: 0.5167\n",
      "Epoch 47/100\n",
      "3000/3000 [==============================] - 1s 373us/step - loss: 0.6964 - acc: 0.5213\n",
      "Epoch 48/100\n",
      "3000/3000 [==============================] - 1s 363us/step - loss: 0.6966 - acc: 0.5177\n",
      "Epoch 49/100\n",
      "3000/3000 [==============================] - 1s 368us/step - loss: 0.7027 - acc: 0.5053\n",
      "Epoch 50/100\n",
      "3000/3000 [==============================] - 1s 369us/step - loss: 0.6925 - acc: 0.5270\n",
      "Epoch 51/100\n",
      "3000/3000 [==============================] - 1s 363us/step - loss: 0.6941 - acc: 0.5223\n",
      "Epoch 52/100\n",
      "3000/3000 [==============================] - 1s 365us/step - loss: 0.6971 - acc: 0.5233\n",
      "Epoch 53/100\n",
      "3000/3000 [==============================] - 1s 344us/step - loss: 0.6989 - acc: 0.5180\n",
      "Epoch 54/100\n",
      "3000/3000 [==============================] - 1s 340us/step - loss: 0.6970 - acc: 0.5110\n",
      "Epoch 55/100\n",
      "3000/3000 [==============================] - 1s 352us/step - loss: 0.6974 - acc: 0.5100\n",
      "Epoch 56/100\n",
      "3000/3000 [==============================] - 2s 604us/step - loss: 0.7044 - acc: 0.5017\n",
      "Epoch 57/100\n",
      "3000/3000 [==============================] - 1s 369us/step - loss: 0.7034 - acc: 0.5043\n",
      "Epoch 58/100\n",
      "3000/3000 [==============================] - 1s 425us/step - loss: 0.6985 - acc: 0.5130\n",
      "Epoch 59/100\n",
      "3000/3000 [==============================] - 1s 453us/step - loss: 0.6985 - acc: 0.5077\n",
      "Epoch 60/100\n",
      "3000/3000 [==============================] - 1s 385us/step - loss: 0.7015 - acc: 0.5057\n",
      "Epoch 61/100\n",
      "3000/3000 [==============================] - 1s 358us/step - loss: 0.6980 - acc: 0.5130\n",
      "Epoch 62/100\n",
      "3000/3000 [==============================] - 1s 361us/step - loss: 0.6957 - acc: 0.5140\n",
      "Epoch 63/100\n",
      "3000/3000 [==============================] - 1s 374us/step - loss: 0.6971 - acc: 0.5087\n",
      "Epoch 64/100\n",
      "3000/3000 [==============================] - 2s 542us/step - loss: 0.6947 - acc: 0.5227\n",
      "Epoch 65/100\n",
      "3000/3000 [==============================] - 1s 423us/step - loss: 0.6981 - acc: 0.5077\n",
      "Epoch 66/100\n",
      "3000/3000 [==============================] - 1s 346us/step - loss: 0.6979 - acc: 0.5077\n",
      "Epoch 67/100\n",
      "3000/3000 [==============================] - 1s 370us/step - loss: 0.6970 - acc: 0.5100\n",
      "Epoch 68/100\n",
      "3000/3000 [==============================] - 1s 331us/step - loss: 0.6995 - acc: 0.5133\n",
      "Epoch 69/100\n",
      "3000/3000 [==============================] - 1s 349us/step - loss: 0.7011 - acc: 0.5217\n",
      "Epoch 70/100\n",
      "3000/3000 [==============================] - 1s 340us/step - loss: 0.6998 - acc: 0.5113\n",
      "Epoch 71/100\n",
      "3000/3000 [==============================] - 1s 339us/step - loss: 0.6964 - acc: 0.5123\n",
      "Epoch 72/100\n",
      "3000/3000 [==============================] - 1s 334us/step - loss: 0.6981 - acc: 0.4977\n",
      "Epoch 73/100\n",
      "3000/3000 [==============================] - ETA: 0s - loss: 0.6972 - acc: 0.526 - 1s 355us/step - loss: 0.6966 - acc: 0.5290\n",
      "Epoch 74/100\n",
      "3000/3000 [==============================] - 1s 344us/step - loss: 0.6994 - acc: 0.4957\n",
      "Epoch 75/100\n",
      "3000/3000 [==============================] - 1s 367us/step - loss: 0.6958 - acc: 0.5167\n",
      "Epoch 76/100\n",
      "3000/3000 [==============================] - 1s 462us/step - loss: 0.6945 - acc: 0.5177\n",
      "Epoch 77/100\n",
      "3000/3000 [==============================] - 2s 545us/step - loss: 0.6991 - acc: 0.5163\n",
      "Epoch 78/100\n",
      "3000/3000 [==============================] - 1s 430us/step - loss: 0.6965 - acc: 0.5223\n",
      "Epoch 79/100\n",
      "3000/3000 [==============================] - 1s 465us/step - loss: 0.6950 - acc: 0.5213\n",
      "Epoch 80/100\n",
      "3000/3000 [==============================] - 1s 385us/step - loss: 0.6981 - acc: 0.4980\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 1s 333us/step - loss: 0.6917 - acc: 0.5293\n",
      "Epoch 82/100\n",
      "3000/3000 [==============================] - 1s 316us/step - loss: 0.6960 - acc: 0.5163\n",
      "Epoch 83/100\n",
      "3000/3000 [==============================] - 1s 309us/step - loss: 0.6945 - acc: 0.5177\n",
      "Epoch 84/100\n",
      "3000/3000 [==============================] - 1s 301us/step - loss: 0.7027 - acc: 0.5043\n",
      "Epoch 85/100\n",
      "3000/3000 [==============================] - 1s 302us/step - loss: 0.6977 - acc: 0.5150\n",
      "Epoch 86/100\n",
      "3000/3000 [==============================] - 1s 308us/step - loss: 0.6928 - acc: 0.5180\n",
      "Epoch 87/100\n",
      "3000/3000 [==============================] - 1s 306us/step - loss: 0.7010 - acc: 0.5050\n",
      "Epoch 88/100\n",
      "3000/3000 [==============================] - 1s 306us/step - loss: 0.6950 - acc: 0.5333\n",
      "Epoch 89/100\n",
      "3000/3000 [==============================] - 1s 308us/step - loss: 0.6943 - acc: 0.5250\n",
      "Epoch 90/100\n",
      "3000/3000 [==============================] - 1s 303us/step - loss: 0.6974 - acc: 0.5040\n",
      "Epoch 91/100\n",
      "3000/3000 [==============================] - 1s 304us/step - loss: 0.6971 - acc: 0.5157\n",
      "Epoch 92/100\n",
      "3000/3000 [==============================] - 1s 301us/step - loss: 0.7003 - acc: 0.5213\n",
      "Epoch 93/100\n",
      "3000/3000 [==============================] - 1s 306us/step - loss: 0.7020 - acc: 0.5020\n",
      "Epoch 94/100\n",
      "3000/3000 [==============================] - 1s 306us/step - loss: 0.6983 - acc: 0.5080\n",
      "Epoch 95/100\n",
      "3000/3000 [==============================] - 1s 303us/step - loss: 0.6942 - acc: 0.5317\n",
      "Epoch 96/100\n",
      "3000/3000 [==============================] - 1s 304us/step - loss: 0.6967 - acc: 0.5183\n",
      "Epoch 97/100\n",
      "3000/3000 [==============================] - 1s 304us/step - loss: 0.6957 - acc: 0.5330\n",
      "Epoch 98/100\n",
      "3000/3000 [==============================] - 1s 300us/step - loss: 0.6981 - acc: 0.4920\n",
      "Epoch 99/100\n",
      "3000/3000 [==============================] - 1s 307us/step - loss: 0.6935 - acc: 0.5267\n",
      "Epoch 100/100\n",
      "3000/3000 [==============================] - 1s 304us/step - loss: 0.6968 - acc: 0.5223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181e3f5fd0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 65us/step\n",
      "[Train] acc: 47.50%\n",
      "1098/1098 [==============================] - 0s 31us/step\n",
      "[Test] acc: 59.84%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_train, Y_train)\n",
    "print(\"[Train] %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "print(\"[Test] %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
